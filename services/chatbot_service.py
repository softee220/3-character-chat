"""
ğŸ¯ ì±—ë´‡ ì„œë¹„ìŠ¤ - êµ¬í˜„ íŒŒì¼

ì´ íŒŒì¼ì€ ì±—ë´‡ì˜ í•µì‹¬ AI ë¡œì§ì„ ë‹´ë‹¹í•©ë‹ˆë‹¤.
ì•„ë˜ ì•„í‚¤í…ì²˜ë¥¼ ì°¸ê³ í•˜ì—¬ ì§ì ‘ ì„¤ê³„í•˜ê³  êµ¬í˜„í•˜ì„¸ìš”.

ğŸ“ ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜:

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. ì´ˆê¸°í™” ë‹¨ê³„ (ChatbotService.__init__)                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  - OpenAI Client ìƒì„±                                    â”‚
â”‚  - ChromaDB ì—°ê²° (ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤)                       â”‚
â”‚  - LangChain Memory ì´ˆê¸°í™” (ëŒ€í™” ê¸°ë¡ ê´€ë¦¬)               â”‚
â”‚  - Config íŒŒì¼ ë¡œë“œ                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. RAG íŒŒì´í”„ë¼ì¸ (generate_response ë‚´ë¶€)               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                          â”‚
â”‚  ì‚¬ìš©ì ì§ˆë¬¸ "í•™ì‹ ì¶”ì²œí•´ì¤˜"                              â”‚
â”‚       â†“                                                  â”‚
â”‚  [_create_embedding()]                                   â”‚
â”‚       â†“                                                  â”‚
â”‚  ì§ˆë¬¸ ë²¡í„°: [0.12, -0.34, ..., 0.78]  (3072ì°¨ì›)        â”‚
â”‚       â†“                                                  â”‚
â”‚  [_search_similar()]  â† ChromaDB ê²€ìƒ‰                    â”‚
â”‚       â†“                                                  â”‚
â”‚  ê²€ìƒ‰ ê²°ê³¼: "í•™ì‹ì€ ê³¤ìê°€ê°€ ë§›ìˆì–´" (ìœ ì‚¬ë„: 0.87)        â”‚
â”‚       â†“                                                  â”‚
â”‚  [_build_prompt()]                                       â”‚
â”‚       â†“                                                  â”‚
â”‚  ìµœì¢… í”„ë¡¬í”„íŠ¸ = ì‹œìŠ¤í…œ ì„¤ì • + RAG ì»¨í…ìŠ¤íŠ¸ + ì§ˆë¬¸        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. LLM ì‘ë‹µ ìƒì„±                                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  OpenAI GPT-4 API í˜¸ì¶œ                                   â”‚
â”‚       â†“                                                  â”‚
â”‚  "í•™ì‹ì€ ê³¤ìê°€ì—ì„œ ë¨¹ëŠ” ê²Œ ì œì¼ ì¢‹ì•„! ëˆê¹ŒìŠ¤ê°€ ì¸ê¸°ì•¼"    â”‚
â”‚       â†“                                                  â”‚
â”‚  [ì„ íƒ: ì´ë¯¸ì§€ ê²€ìƒ‰]                                      â”‚
â”‚       â†“                                                  â”‚
â”‚  ì‘ë‹µ ë°˜í™˜: {reply: "...", image: "..."}                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. ë©”ëª¨ë¦¬ ì €ì¥ (LangChain Memory)                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ëŒ€í™” ê¸°ë¡ì— ì§ˆë¬¸-ì‘ë‹µ ì €ì¥                               â”‚
â”‚  ë‹¤ìŒ ëŒ€í™”ì—ì„œ ì»¨í…ìŠ¤íŠ¸ë¡œ í™œìš©                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


ğŸ’¡ í•µì‹¬ êµ¬í˜„ ê³¼ì œ:

1. **Embedding ìƒì„±**
   - OpenAI APIë¥¼ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°ë¡œ ë³€í™˜
   - ëª¨ë¸: text-embedding-3-large (3072ì°¨ì›)

2. **RAG ê²€ìƒ‰ ì•Œê³ ë¦¬ì¦˜** â­ ê°€ì¥ ì¤‘ìš”!
   - ChromaDBì—ì„œ ìœ ì‚¬ ë²¡í„° ê²€ìƒ‰
   - ìœ ì‚¬ë„ ê³„ì‚°: similarity = 1 / (1 + distance)
   - threshold ì´ìƒì¸ ë¬¸ì„œë§Œ ì„ íƒ

3. **LLM í”„ë¡¬í”„íŠ¸ ì„¤ê³„**
   - ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ (ìºë¦­í„° ì„¤ì •)
   - RAG ì»¨í…ìŠ¤íŠ¸ í†µí•©
   - ëŒ€í™” ê¸°ë¡ í¬í•¨

4. **ëŒ€í™” ë©”ëª¨ë¦¬ ê´€ë¦¬**
   - LangChainì˜ ConversationSummaryBufferMemory ì‚¬ìš©
   - ëŒ€í™”ê°€ ê¸¸ì–´ì§€ë©´ ìë™ìœ¼ë¡œ ìš”ì•½


ğŸ“š ì°¸ê³  ë¬¸ì„œ:
- ARCHITECTURE.md: ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜ ìƒì„¸ ì„¤ëª…
- IMPLEMENTATION_GUIDE.md: ë‹¨ê³„ë³„ êµ¬í˜„ ê°€ì´ë“œ
- README.md: í”„ë¡œì íŠ¸ ê°œìš”


âš ï¸ ì£¼ì˜ì‚¬í•­:
- ì´ íŒŒì¼ì˜ êµ¬ì¡°ëŠ” ê°€ì´ë“œì¼ ë¿ì…ë‹ˆë‹¤
- ììœ ë¡­ê²Œ ì¬ì„¤ê³„í•˜ê³  í™•ì¥í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤
- ë‹¨, generate_response() í•¨ìˆ˜ ì‹œê·¸ë‹ˆì²˜ëŠ” ìœ ì§€í•´ì•¼ í•©ë‹ˆë‹¤
  (app.pyì—ì„œ í˜¸ì¶œí•˜ê¸° ë•Œë¬¸)
"""

import os
from pathlib import Path
from dotenv import load_dotenv
import json
import re
from typing import Dict, List, Tuple, Optional
import chromadb
from openai import OpenAI
from .emotion_analyzer import EmotionAnalyzer, ReportGenerator
from .rag_service import RAGService
from .config_loader import ConfigLoader
# from langchain_community.memory import ConversationSummaryBufferMemory  # Not available in current LangChain version
# from langchain.llms import OpenAI as LangChainOpenAI  # Not available in current LangChain version

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ
BASE_DIR = Path(__file__).resolve().parent.parent


class ChatbotService:

    
    def __init__(self):
 
        print("[ChatbotService] ì´ˆê¸°í™” ì¤‘... ")
        
        # 1. Config ë¡œë“œ
        self.config = ConfigLoader.load_config()
        
        # 2. OpenAI Client ì´ˆê¸°í™”
        api_key = os.getenv("OPENAI_API_KEY")
        if api_key:
            self.client = OpenAI(api_key=api_key)
        else:
            self.client = None
            print("[WARNING] OPENAI_API_KEY ë¯¸ì„¤ì •: LLM í˜¸ì¶œì„ ë¹„í™œì„±í™”í•©ë‹ˆë‹¤.")
        
        # 3. RAG ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
        self.rag_service = RAGService(self.client)
        
        # 4. LangChain Memory ì´ˆê¸°í™” (API í‚¤ê°€ ìˆì„ ë•Œë§Œ)
        self.memory = None
        if api_key:
            try:
                llm = LangChainOpenAI(openai_api_key=api_key, temperature=0.7)
                self.memory = ConversationSummaryBufferMemory(
                    llm=llm,
                    max_token_limit=1000,
                    return_messages=True
                )
            except Exception as e:
                print(f"[WARNING] ë©”ëª¨ë¦¬ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        
        # 5. ê°ì • ë¶„ì„ ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
        self.emotion_analyzer = EmotionAnalyzer()
        self.report_generator = ReportGenerator()
        
        # 6. DSM ìƒíƒœ ê´€ë¦¬ ë³€ìˆ˜ ì´ˆê¸°í™”
        self.dialogue_state = 'INTRO'  # ëŒ€í™” ìƒíƒœ (INTRO, RECALL_ATTACHMENT, RECALL_REGRET, etc.)
        self.turn_count = 0  # ëŒ€í™” í„´ ìˆ˜ ì¶”ì 
        self.stop_request_count = 0  # ì‚¬ìš©ì ëŒ€í™” ì¤‘ë‹¨ ìš”ì²­ íšŸìˆ˜
        
        print("[ChatbotService] ì´ˆê¸°í™” ì™„ë£Œ")
    
    
    def _build_prompt(self, user_message: str, context: str = None, username: str = "ì‚¬ìš©ì"):
 
        # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        system_prompt = self.config.get('system_prompt', {})
        base_prompt = system_prompt.get('base', 'ë‹¹ì‹ ì€ í™˜ìŠ¹ì—°ì• íŒ€ ë§‰ë‚´ PDê°€ ëœ ì¹œêµ¬ì…ë‹ˆë‹¤.')
        rules = system_prompt.get('rules', [])
        
        # ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        prompt_parts = [base_prompt]
        
        # ê·œì¹™ ì¶”ê°€
        if rules:
            prompt_parts.append("\n".join([f"- {rule}" for rule in rules]))
        
        # RAG ì»¨í…ìŠ¤íŠ¸ ì¶”ê°€
        if context:
            prompt_parts.append(f"\n[ì°¸ê³  ì •ë³´]\n{context}")
        
        # ëŒ€í™” ê¸°ë¡ ì¶”ê°€ (ì„ íƒ)
        if self.memory:
            try:
                memory_vars = self.memory.load_memory_variables({})
                if memory_vars and 'history' in memory_vars:
                    prompt_parts.append(f"\n[ëŒ€í™” ê¸°ë¡]\n{memory_vars['history']}")
            except Exception as e:
                print(f"[WARNING] ë©”ëª¨ë¦¬ ë¡œë“œ ì‹¤íŒ¨: {e}")
        
        # ëŒ€í™” ì§€ì¹¨ ì¶”ê°€
        prompt_parts.append("\nëŒ€í™” ì§€ì¹¨:")
        prompt_parts.append("- ì¹œêµ¬ì²˜ëŸ¼ í¸í•˜ê²Œ ë°˜ë§ë¡œ ëŒ€í™”í•´")
        prompt_parts.append("- ë„ˆë¬´ ìƒì„¸í•˜ê²Œ ê³„ì† ë¬¼ì–´ë³´ì§€ ë§ê³ , ì ë‹¹í•œ íƒ€ì´ë°ì— ë‹¤ë¥¸ ì£¼ì œë¡œ ë„˜ì–´ê°€")
        prompt_parts.append("- ì—°ì•  ì´ì•¼ê¸°ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ì´ëŒì–´ë‚´ë˜, ë¬´ë¦¬í•˜ê²Œ ëŒì–´ë‚´ì§€ ë§ˆ")
        prompt_parts.append("- ì´ëª¨í‹°ì½˜ì€ ìµœì†Œí•œìœ¼ë¡œ ì‚¬ìš©í•´")
        
        # Redirection Rule ë° ì£¼ì œ ì´íƒˆ ë°©ì§€ ì§€ì¹¨ ì¶”ê°€
        prompt_parts.append("\n[PD ì¹œêµ¬ ê·œì¹™ ê°•í™”]:")
        prompt_parts.append("- ë„ˆëŠ” í™˜ìŠ¹ì—°ì•  PD ì¹œêµ¬ë¡œì„œ, ì˜¤ì§ ì „ì• ì¸(X)ê³¼ì˜ ì—°ì•  ì´ì•¼ê¸°ì—ë§Œ ì§‘ì¤‘í•´ì•¼ í•´.")
        prompt_parts.append("\n[ì£¼ì œ ë³µê·€ ê·œì¹™]:")
        prompt_parts.append("- ì‚¬ìš©ìê°€ í˜„ì• ì¸ ë˜ëŠ” ì „ì• ì¸ê³¼ ë¬´ê´€í•œ ì£¼ì œ(ì¼ë°˜ ì¼ìƒ, ë¯¸ë˜ ê³„íš ë“±)ë¡œ ëŒ€í™”ê°€ ì´íƒˆí•˜ë©´, 'AI ë¶„ì„ ë²”ìœ„ ë°–' ë˜ëŠ” 'ê¸°íšì•ˆ ë°ì´í„°'ë¥¼ í•‘ê³„ë¡œ ì¹œê·¼í•˜ê²Œ ëŒ€í™”ë¥¼ ì „ì• ì¸ ì´ì•¼ê¸°ë¡œ ë³µê·€ì‹œì¼œì•¼ í•´. ì ˆëŒ€ë¡œ ë”±ë”±í•˜ê²Œ ëŠê±°ë‚˜ ê°•ì••ì ìœ¼ë¡œ ë“¤ë¦¬ë©´ ì•ˆ ë¼.")
        
        # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
        prompt_parts.append(f"\n{username}: {user_message}")
        
        return "\n".join(prompt_parts)
    
    
    def generate_response(self, user_message: str, username: str = "ì‚¬ìš©ì") -> dict:
        
        
        # ì—¬ê¸°ì— ì „ì²´ íŒŒì´í”„ë¼ì¸ êµ¬í˜„
        # ìœ„ì˜ ë‹¨ê³„ë¥¼ ì°¸ê³ í•˜ì—¬ ììœ ë¡­ê²Œ ì„¤ê³„í•˜ì„¸ìš”
        
        try:
            print(f"\n{'='*50}")
            print(f"[USER] {username}: {user_message}")
            
            # [1ë‹¨ê³„] ì´ˆê¸° ë©”ì‹œì§€ ì²˜ë¦¬
            if user_message.strip().lower() == "init":
                bot_name = self.config.get('name', 'í™˜ìŠ¹ì—°ì•  PD ì¹œêµ¬')
                # ë„ì…ë¶€: INTRO ìƒíƒœë¡œ ì‹œì‘
                self.dialogue_state = 'INTRO'
                self.turn_count = 0
                self.stop_request_count = 0
                return {
                    'reply': f"ì•¼, {username}! ìš”ì¦˜ ë‚˜ ì¼ ì¬ë°Œì–´ ì£½ê² ì–´ã…‹ã…‹ ë‚˜ ë“œë””ì–´ í™˜ìŠ¹ì—°ì•  ë§‰ë‚´ PD ëë‹¤ë‹ˆê¹Œ! ê·¼ë° ì›ƒê¸´ ê²Œ, ìš”ì¦˜ ê±°ê¸°ì„œ AI ë„ì… ì–˜ê¸°ê°€ ì§„ì§œ ë§ì•„. ë‹¤ìŒ ì‹œì¦Œì—” ë¬´ë ¤ â€˜Xì™€ì˜ ë¯¸ë ¨ë„ ì¸¡ì • AIâ€™ ê°™ì€ ê²ƒë„ ë„£ëŠ”ëŒ€ã…‹ã…‹ã…‹ ì™„ì „ ì‹ ë°•í•˜ì§€ ì•Šì•„? ë‚´ê°€ ìš”ì¦˜ ê·¸ê±° ê´€ë ¨í•´ì„œ ì—°ì•  ì‚¬ë¡€ ëª¨ìœ¼ê³  ìˆê±°ë“ . ê°€ë§Œ ìƒê°í•´ë³´ë‹ˆê¹Œâ€¦ ë„ˆ ì–˜ê¸°ê°€ ë”±ì´ì•¼. ì•„ì§ í…ŒìŠ¤íŠ¸ ë²„ì „ì´ë¼ ì§„ì§œ ì¬ë¯¸ì‚¼ì•„ ë³´ëŠ” ê±°ì•¼. ë¶€ë‹´ ê°–ì§€ë§ˆë§ˆ ê·¸ëƒ¥ ì¹œêµ¬í•œí…Œ ì˜›ë‚  ì–˜ê¸°í•˜ë“¯ì´ í¸í•˜ê²Œ ë§í•´ì¤˜ ã…‹ã…‹ ë„ˆ ì˜ˆì „ì— ê·¸ X ìˆì–ì•„. í˜¹ì‹œ Xë‘ ìˆì—ˆë˜ ì¼ ì–˜ê¸°í•´ì¤„ ìˆ˜ ìˆì–´?",

                    'image': None
                }
            
            # ì¼ë°˜ ë©”ì‹œì§€ì˜ ê²½ìš° turn_count ì¦ê°€
            self.turn_count += 1
            
            # [2ë‹¨ê³„] RAG ê²€ìƒ‰ ìˆ˜í–‰
            #ìš°ë¦¬ëŠ” RAG ê²€ìƒ‰ ë§¤ ì§ˆë¬¸ë§ˆë‹¤ ì‚¬ìš© í•˜ì§€ ì•ŠìŒ ë¶ˆí•„ìš” 
            context, similarity, metadata = self.rag_service.search_similar(
                query=user_message,
                threshold=0.45,
                top_k=5
            )
            
            has_context = (context is not None)
            print(f"[RAG] Context found: {has_context}")
            if has_context:
                print(f"[RAG] Similarity: {similarity:.4f}")
                print(f"[RAG] Context: {context[:100]}...")
            
            # [3ë‹¨ê³„] ì—°ì•  ê°ì • ë¶„ì„ ìˆ˜í–‰
            analysis_results = self.emotion_analyzer.calculate_regret_index(user_message)
            print(f"[ANALYSIS] ë¯¸ë ¨ë„: {analysis_results['total']:.1f}%")
            
            # [4ë‹¨ê³„] í”„ë¡¬í”„íŠ¸ êµ¬ì„±
            prompt = self._build_prompt(
                user_message=user_message,
                context=context,
                username=username
            )
            
            # [5ë‹¨ê³„] LLM API í˜¸ì¶œ
            # ë¶ˆí•„ìš”í•œ ì¤‘ë³µì¸ê°€?
            if self.client:
                print(f"[LLM] Calling API...")
                response = self.client.chat.completions.create(
                    model="gpt-4o-mini",
                    messages=[
                        {"role": "system", "content": "ë‹¹ì‹ ì€ í™˜ìŠ¹ì—°ì• íŒ€ ë§‰ë‚´ PDê°€ ëœ ì¹œêµ¬ì…ë‹ˆë‹¤. ì‚¬ìš©ìì™€ ë°˜ë§ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ëŒ€í™”í•˜ë©°, ì—°ì•  ì´ì•¼ê¸°ë¥¼ ë“£ê³  ë¯¸ë ¨ë„ë¥¼ ë¶„ì„í•´ì£¼ëŠ” ì—­í• ì„ í•©ë‹ˆë‹¤. ì¹œêµ¬ì²˜ëŸ¼ í¸í•˜ê²Œ ëŒ€í™”í•˜ê³ , ì´ëª¨í‹°ì½˜ì€ ìµœì†Œí•œìœ¼ë¡œ ì‚¬ìš©í•˜ì„¸ìš”. ë„ˆë¬´ ìƒì„¸í•˜ê²Œ ê³„ì† ë¬¼ì–´ë³´ì§€ ë§ê³ , ì ë‹¹í•œ íƒ€ì´ë°ì— ë‹¤ë¥¸ ì£¼ì œë¡œ ë„˜ì–´ê°€ê±°ë‚˜ ë¶„ì„ ê²°ê³¼ë¥¼ ì œì‹œí•˜ì„¸ìš”. ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™” íë¦„ì„ ìœ ì§€í•˜ì„¸ìš”."},
                        {"role": "user", "content": prompt}
                    ],
                    temperature=0.7,
                    max_tokens=500
                )
                reply = response.choices[0].message.content
            else:
                # LLM ë¹„í™œì„±í™” ì‹œ ê¸°ë³¸ ì‘ë‹µ
                reply = "AI ì—°ì•  ë¶„ì„ ì—ì´ì „íŠ¸ ë°ëª¨ ëª¨ë“œì•¼. í™˜ê²½ë³€ìˆ˜ ì„¤ì • í›„ ë” ì •êµí•œ ë¶„ì„ì´ ê°€ëŠ¥í•´! ë¨¼ì € ì–´ë–¤ ì´ì•¼ê¸°ë¶€í„° ì‹œì‘í• ê¹Œ?"
            
            # [6ë‹¨ê³„] ê°ì • ë¦¬í¬íŠ¸ ìƒì„± (íŠ¹ì • ì¡°ê±´ì—ì„œ)
            if any(keyword in user_message.lower() for keyword in ["ë¶„ì„", "ë¦¬í¬íŠ¸", "ê²°ê³¼", "ì–´ë•Œ", "ì–´ë–¤"]):
                if analysis_results['total'] > 0:  # ë¶„ì„ ê²°ê³¼ê°€ ìˆì„ ë•Œë§Œ
                    report = self.report_generator.generate_emotion_report(analysis_results, username)
                    reply += f"\n\n{report}"
            
            # [7ë‹¨ê³„] ë©”ëª¨ë¦¬ ì €ì¥
            if self.memory:
                try:
                    self.memory.save_context(
                        {"input": user_message},
                        {"output": reply}
                    )
                except Exception as e:
                    print(f"[WARNING] ë©”ëª¨ë¦¬ ì €ì¥ ì‹¤íŒ¨: {e}")
            
            print(f"[BOT] {reply[:100]}...")
            print(f"{'='*50}\n")
            
            # [8ë‹¨ê³„] ì‘ë‹µ ë°˜í™˜
            return {
                'reply': reply,
                'image': None
            }
            
        except Exception as e:
            print(f"[ERROR] ì‘ë‹µ ìƒì„± ì‹¤íŒ¨: {e}")
            return {
                'reply': "ì£„ì†¡í•´ìš”, ì¼ì‹œì ì¸ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆì–´ìš”. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.",
                'image': None
            }


# ============================================================================
# ì‹±ê¸€í†¤ íŒ¨í„´
# ============================================================================
# ChatbotService ì¸ìŠ¤í„´ìŠ¤ë¥¼ ì•± ì „ì²´ì—ì„œ ì¬ì‚¬ìš©
# (ë§¤ë²ˆ ìƒˆë¡œ ì´ˆê¸°í™”í•˜ë©´ ë¹„íš¨ìœ¨ì )

_chatbot_service = None

def get_chatbot_service():
    """
    ì±—ë´‡ ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜ (ì‹±ê¸€í†¤)
    
    ì²« í˜¸ì¶œ ì‹œ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±, ì´í›„ ì¬ì‚¬ìš©
    """
    global _chatbot_service
    if _chatbot_service is None:
        _chatbot_service = ChatbotService()
    return _chatbot_service


# ============================================================================
# í…ŒìŠ¤íŠ¸ìš© ë©”ì¸ í•¨ìˆ˜
# ============================================================================

if __name__ == "__main__":
    """
    ë¡œì»¬ í…ŒìŠ¤íŠ¸ìš©
    
    ì‹¤í–‰ ë°©ë²•:
    python services/chatbot_service.py
    """
    print("ì±—ë´‡ ì„œë¹„ìŠ¤ í…ŒìŠ¤íŠ¸")
    print("=" * 50)
    
    service = get_chatbot_service()
    
    # ì´ˆê¸°í™” í…ŒìŠ¤íŠ¸
    response = service.generate_response("init", "í…ŒìŠ¤í„°")
    print(f"ì´ˆê¸° ì‘ë‹µ: {response}")
    
    # ì¼ë°˜ ëŒ€í™” í…ŒìŠ¤íŠ¸
    response = service.generate_response("ì•ˆë…•í•˜ì„¸ìš”!", "í…ŒìŠ¤í„°")
    print(f"ì‘ë‹µ: {response}")
