"""
ğŸ¯ ì±—ë´‡ ì„œë¹„ìŠ¤ - êµ¬í˜„ íŒŒì¼

ì´ íŒŒì¼ì€ ì±—ë´‡ì˜ í•µì‹¬ AI ë¡œì§ì„ ë‹´ë‹¹í•©ë‹ˆë‹¤.
ì•„ë˜ ì•„í‚¤í…ì²˜ë¥¼ ì°¸ê³ í•˜ì—¬ ì§ì ‘ ì„¤ê³„í•˜ê³  êµ¬í˜„í•˜ì„¸ìš”.

ğŸ“ ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜:

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. ì´ˆê¸°í™” ë‹¨ê³„ (ChatbotService.__init__)                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  - OpenAI Client ìƒì„±                                    â”‚
â”‚  - ChromaDB ì—°ê²° (ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤)                       â”‚
â”‚  - LangChain Memory ì´ˆê¸°í™” (ëŒ€í™” ê¸°ë¡ ê´€ë¦¬)               â”‚
â”‚  - Config íŒŒì¼ ë¡œë“œ                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. RAG íŒŒì´í”„ë¼ì¸ (generate_response ë‚´ë¶€)               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                          â”‚
â”‚  ì‚¬ìš©ì ì§ˆë¬¸ "í•™ì‹ ì¶”ì²œí•´ì¤˜"                              â”‚
â”‚       â†“                                                  â”‚
â”‚  [_create_embedding()]                                   â”‚
â”‚       â†“                                                  â”‚
â”‚  ì§ˆë¬¸ ë²¡í„°: [0.12, -0.34, ..., 0.78]  (3072ì°¨ì›)        â”‚
â”‚       â†“                                                  â”‚
â”‚  [_search_similar()]  â† ChromaDB ê²€ìƒ‰                    â”‚
â”‚       â†“                                                  â”‚
â”‚  ê²€ìƒ‰ ê²°ê³¼: "í•™ì‹ì€ ê³¤ìê°€ê°€ ë§›ìˆì–´" (ìœ ì‚¬ë„: 0.87)        â”‚
â”‚       â†“                                                  â”‚
â”‚  [_build_prompt()]                                       â”‚
â”‚       â†“                                                  â”‚
â”‚  ìµœì¢… í”„ë¡¬í”„íŠ¸ = ì‹œìŠ¤í…œ ì„¤ì • + RAG ì»¨í…ìŠ¤íŠ¸ + ì§ˆë¬¸        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. LLM ì‘ë‹µ ìƒì„±                                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  OpenAI GPT-4 API í˜¸ì¶œ                                   â”‚
â”‚       â†“                                                  â”‚
â”‚  "í•™ì‹ì€ ê³¤ìê°€ì—ì„œ ë¨¹ëŠ” ê²Œ ì œì¼ ì¢‹ì•„! ëˆê¹ŒìŠ¤ê°€ ì¸ê¸°ì•¼"    â”‚
â”‚       â†“                                                  â”‚
â”‚  [ì„ íƒ: ì´ë¯¸ì§€ ê²€ìƒ‰]                                      â”‚
â”‚       â†“                                                  â”‚
â”‚  ì‘ë‹µ ë°˜í™˜: {reply: "...", image: "..."}                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. ë©”ëª¨ë¦¬ ì €ì¥ (LangChain Memory)                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ëŒ€í™” ê¸°ë¡ì— ì§ˆë¬¸-ì‘ë‹µ ì €ì¥                               â”‚
â”‚  ë‹¤ìŒ ëŒ€í™”ì—ì„œ ì»¨í…ìŠ¤íŠ¸ë¡œ í™œìš©                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


ğŸ’¡ í•µì‹¬ êµ¬í˜„ ê³¼ì œ:

1. **Embedding ìƒì„±**
   - OpenAI APIë¥¼ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°ë¡œ ë³€í™˜
   - ëª¨ë¸: text-embedding-3-large (3072ì°¨ì›)

2. **RAG ê²€ìƒ‰ ì•Œê³ ë¦¬ì¦˜** â­ ê°€ì¥ ì¤‘ìš”!
   - ChromaDBì—ì„œ ìœ ì‚¬ ë²¡í„° ê²€ìƒ‰
   - ìœ ì‚¬ë„ ê³„ì‚°: similarity = 1 / (1 + distance)
   - threshold ì´ìƒì¸ ë¬¸ì„œë§Œ ì„ íƒ

3. **LLM í”„ë¡¬í”„íŠ¸ ì„¤ê³„**
   - ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ (ìºë¦­í„° ì„¤ì •)
   - RAG ì»¨í…ìŠ¤íŠ¸ í†µí•©
   - ëŒ€í™” ê¸°ë¡ í¬í•¨

4. **ëŒ€í™” ë©”ëª¨ë¦¬ ê´€ë¦¬**
   - LangChainì˜ ConversationSummaryBufferMemory ì‚¬ìš©
   - ëŒ€í™”ê°€ ê¸¸ì–´ì§€ë©´ ìë™ìœ¼ë¡œ ìš”ì•½


ğŸ“š ì°¸ê³  ë¬¸ì„œ:
- ARCHITECTURE.md: ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜ ìƒì„¸ ì„¤ëª…
- IMPLEMENTATION_GUIDE.md: ë‹¨ê³„ë³„ êµ¬í˜„ ê°€ì´ë“œ
- README.md: í”„ë¡œì íŠ¸ ê°œìš”


âš ï¸ ì£¼ì˜ì‚¬í•­:
- ì´ íŒŒì¼ì˜ êµ¬ì¡°ëŠ” ê°€ì´ë“œì¼ ë¿ì…ë‹ˆë‹¤
- ììœ ë¡­ê²Œ ì¬ì„¤ê³„í•˜ê³  í™•ì¥í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤
- ë‹¨, generate_response() í•¨ìˆ˜ ì‹œê·¸ë‹ˆì²˜ëŠ” ìœ ì§€í•´ì•¼ í•©ë‹ˆë‹¤
  (app.pyì—ì„œ í˜¸ì¶œí•˜ê¸° ë•Œë¬¸)
"""

import os
from pathlib import Path
from dotenv import load_dotenv
import json
import re
from typing import Dict, List, Tuple, Optional
import chromadb
from openai import OpenAI
# from langchain_community.memory import ConversationSummaryBufferMemory  # Not available in current LangChain version
# from langchain.llms import OpenAI as LangChainOpenAI  # Not available in current LangChain version

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ
BASE_DIR = Path(__file__).resolve().parent.parent


class ChatbotService:
    """
    ì±—ë´‡ ì„œë¹„ìŠ¤ í´ë˜ìŠ¤
    
    ì´ í´ë˜ìŠ¤ëŠ” ì±—ë´‡ì˜ ëª¨ë“  AI ë¡œì§ì„ ìº¡ìŠí™”í•©ë‹ˆë‹¤.
    
    ì£¼ìš” ì±…ì„:
    1. OpenAI API ê´€ë¦¬
    2. ChromaDB ë²¡í„° ê²€ìƒ‰
    3. LangChain ë©”ëª¨ë¦¬ ê´€ë¦¬
    4. ì‘ë‹µ ìƒì„± íŒŒì´í”„ë¼ì¸
    
    ì§ì ‘ êµ¬í˜„í•´ì•¼ í•  ë©”ì„œë“œ:
    - __init__: ëª¨ë“  êµ¬ì„± ìš”ì†Œ ì´ˆê¸°í™”
    - _load_config: ì„¤ì • íŒŒì¼ ë¡œë“œ
    - _init_chromadb: ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”
    - _create_embedding: í…ìŠ¤íŠ¸ â†’ ë²¡í„° ë³€í™˜
    - _search_similar: RAG ê²€ìƒ‰ ìˆ˜í–‰ (í•µì‹¬!)
    - _build_prompt: í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    - generate_response: ìµœì¢… ì‘ë‹µ ìƒì„± (ëª¨ë“  ë¡œì§ í†µí•©)
    """
    
    def __init__(self):
        """
        ì±—ë´‡ ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
        
        TODO: ë‹¤ìŒ êµ¬ì„± ìš”ì†Œë“¤ì„ ì´ˆê¸°í™”í•˜ì„¸ìš”
        
        1. Config ë¡œë“œ
           - config/chatbot_config.json íŒŒì¼ ì½ê¸°
           - ì±—ë´‡ ì´ë¦„, ì„¤ëª…, ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ë“±
        
        2. OpenAI Client
           - API í‚¤: os.getenv("OPENAI_API_KEY")
           - from openai import OpenAI
           - self.client = OpenAI(api_key=...)
        
        3. ChromaDB
           - í…ìŠ¤íŠ¸ ì„ë² ë”© ì»¬ë ‰ì…˜ ì—°ê²°
           - ê²½ë¡œ: static/data/chatbot/chardb_embedding
           - self.collection = ...
        
        4. LangChain Memory (ì„ íƒ)
           - ConversationSummaryBufferMemory
           - ëŒ€í™” ê¸°ë¡ ê´€ë¦¬
           - self.memory = ...
        
        íŒíŠ¸:
        - ChromaDB: import chromadb
        - LangChain: # from langchain_community.memory import ConversationSummaryBufferMemory  # Not available in current LangChain version
        """
        print("[ChatbotService] ì´ˆê¸°í™” ì¤‘... ")
        
        # 1. Config ë¡œë“œ
        self.config = self._load_config()
        
        # 2. OpenAI Client ì´ˆê¸°í™”
        api_key = os.getenv("OPENAI_API_KEY")
        if api_key:
            self.client = OpenAI(api_key=api_key)
        else:
            self.client = None
            print("[WARNING] OPENAI_API_KEY ë¯¸ì„¤ì •: LLM í˜¸ì¶œì„ ë¹„í™œì„±í™”í•©ë‹ˆë‹¤.")
        
        # 3. ChromaDB ì´ˆê¸°í™”
        self.collection = self._init_chromadb()
        
        # 4. LangChain Memory ì´ˆê¸°í™” (API í‚¤ê°€ ìˆì„ ë•Œë§Œ)
        self.memory = None
        if api_key:
            try:
                llm = LangChainOpenAI(openai_api_key=api_key, temperature=0.7)
                self.memory = ConversationSummaryBufferMemory(
                    llm=llm,
                    max_token_limit=1000,
                    return_messages=True
                )
            except Exception as e:
                print(f"[WARNING] ë©”ëª¨ë¦¬ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        
        # 5. ì—°ì•  ê°ì • ë¶„ì„ì„ ìœ„í•œ í‚¤ì›Œë“œ ë¡œë“œ
        self.emotion_keywords = self._load_emotion_keywords()
        
        print("[ChatbotService] ì´ˆê¸°í™” ì™„ë£Œ")
    
    def _load_emotion_keywords(self) -> Dict[str, List[str]]:
        """ì—°ì•  ê°ì • ë¶„ì„ì„ ìœ„í•œ í‚¤ì›Œë“œ ë¡œë“œ"""
        keywords = {
            "attachment_high": ["ì•„ì§ë„", "ì—¬ì „íˆ", "ì§€ê¸ˆë„", "ìš”ì¦˜ë„", "ê·¸ë¦¬ì›Œ", "ë³´ê³ ì‹¶ì–´", "ìƒê°ë‚˜"],
            "attachment_low": ["ì´ì œ", "ë” ì´ìƒ", "ì‹ ê²½ ì•ˆ ì¨", "ê´€ì‹¬ ì—†ì–´", "ìŠì—ˆì–´", "ì§€ë‚˜ê°„ ì¼"],
            "regret_high": ["ë¯¸ì•ˆí•´", "ì•„ì‰¬ì›Œ", "í›„íšŒë¼", "ì˜ëª»í–ˆì–´", "ë‹¤ì‹œ ëŒì•„ê°€ë©´", "ë” ì˜í–ˆìœ¼ë©´"],
            "regret_low": ["í›„íšŒ ì—†ì–´", "ê·¸ë•Œê°€ ìµœì„ ", "ë§ëŠ” ì„ íƒ", "ë‹¤ì‹œ ëŒì•„ê°€ë„"],
            "unresolved_high": ["ì´í•´ê°€ ì•ˆ ë¼", "ê¶ê¸ˆí•´", "ëª…í™•í•˜ì§€ ì•Šì•„", "ëë‚˜ì§€ ì•Šì€", "í•´ê²°ë˜ì§€ ì•Šì€"],
            "unresolved_low": ["ì´í•´í–ˆì–´", "ì •ë¦¬ëì–´", "ëª…í™•í•´", "í•´ê²°ëì–´", "ëë‚¬ì–´"],
            "comparison_high": ["ë¹„êµí•´", "ê·¸ ì‚¬ëŒë§Œí¼ì€", "ì´ì „ê³¼ ë¹„êµí•˜ë©´", "ìƒˆë¡œìš´ ì‚¬ëŒê³¼"],
            "comparison_low": ["ë¹„êµí•˜ì§€ ì•Šì•„", "ê°ì ë‹¤ë¥¸", "ë…ë¦½ì ìœ¼ë¡œ", "ë³„ê°œë¡œ"],
            "avoidance_high": ["í”¼í•˜ê³  ì‹¶ì–´", "íšŒí”¼í•˜ê³  ì‹¶ì–´", "ì–˜ê¸° í•˜ê¸° ì‹«ì–´", "ë§Œë‚˜ê¸° ì‹«ì–´"],
            "approach_high": ["ë§Œë‚˜ê³  ì‹¶ì–´", "ì—°ë½í•˜ê³  ì‹¶ì–´", "ìì—°ìŠ¤ëŸ½ê²Œ", "ê´œì°®ì•„"]
        }
        return keywords
    
    def _analyze_attachment_level(self, user_message: str) -> float:
        """ì• ì°©ë„ ë¶„ì„ (0-100)"""
        high_keywords = self.emotion_keywords["attachment_high"]
        low_keywords = self.emotion_keywords["attachment_low"]
        
        high_score = sum(1 for keyword in high_keywords if keyword in user_message)
        low_score = sum(1 for keyword in low_keywords if keyword in user_message)
        
        if high_score > 0 and low_score == 0:
            return min(80 + (high_score * 5), 100)
        elif low_score > 0 and high_score == 0:
            return max(20 - (low_score * 5), 0)
        else:
            return 50  # ì¤‘ë¦½
    
    def _analyze_regret_level(self, user_message: str) -> float:
        """í›„íšŒë„ ë¶„ì„ (0-100)"""
        high_keywords = self.emotion_keywords["regret_high"]
        low_keywords = self.emotion_keywords["regret_low"]
        
        high_score = sum(1 for keyword in high_keywords if keyword in user_message)
        low_score = sum(1 for keyword in low_keywords if keyword in user_message)
        
        if high_score > 0 and low_score == 0:
            return min(80 + (high_score * 5), 100)
        elif low_score > 0 and high_score == 0:
            return max(20 - (low_score * 5), 0)
        else:
            return 50  # ì¤‘ë¦½
    
    def _analyze_unresolved_feelings(self, user_message: str) -> float:
        """ë¯¸í•´ê²°ê° ë¶„ì„ (0-100)"""
        high_keywords = self.emotion_keywords["unresolved_high"]
        low_keywords = self.emotion_keywords["unresolved_low"]
        
        high_score = sum(1 for keyword in high_keywords if keyword in user_message)
        low_score = sum(1 for keyword in low_keywords if keyword in user_message)
        
        if high_score > 0 and low_score == 0:
            return min(80 + (high_score * 5), 100)
        elif low_score > 0 and high_score == 0:
            return max(20 - (low_score * 5), 0)
        else:
            return 50  # ì¤‘ë¦½
    
    def _analyze_comparison_standard(self, user_message: str) -> float:
        """ë¹„êµ ê¸°ì¤€ ë¶„ì„ (0-100)"""
        high_keywords = self.emotion_keywords["comparison_high"]
        low_keywords = self.emotion_keywords["comparison_low"]
        
        high_score = sum(1 for keyword in high_keywords if keyword in user_message)
        low_score = sum(1 for keyword in low_keywords if keyword in user_message)
        
        if high_score > 0 and low_score == 0:
            return min(80 + (high_score * 5), 100)
        elif low_score > 0 and high_score == 0:
            return max(20 - (low_score * 5), 0)
        else:
            return 50  # ì¤‘ë¦½
    
    def _analyze_avoidance_approach(self, user_message: str) -> float:
        """íšŒí”¼/ì ‘ê·¼ ë¶„ì„ (0-100)"""
        avoidance_keywords = self.emotion_keywords["avoidance_high"]
        approach_keywords = self.emotion_keywords["approach_high"]
        
        avoidance_score = sum(1 for keyword in avoidance_keywords if keyword in user_message)
        approach_score = sum(1 for keyword in approach_keywords if keyword in user_message)
        
        if avoidance_score > approach_score:
            return min(80 + (avoidance_score * 5), 100)  # íšŒí”¼
        elif approach_score > avoidance_score:
            return max(20 - (approach_score * 5), 0)  # ì ‘ê·¼
        else:
            return 50  # ì¤‘ë¦½
    
    def _calculate_regret_index(self, user_message: str) -> Dict[str, float]:
        """ì¢…í•© ë¯¸ë ¨ë„ ì§€ìˆ˜ ê³„ì‚°"""
        attachment = self._analyze_attachment_level(user_message)
        regret = self._analyze_regret_level(user_message)
        unresolved = self._analyze_unresolved_feelings(user_message)
        comparison = self._analyze_comparison_standard(user_message)
        avoidance = self._analyze_avoidance_approach(user_message)
        
        # ê°€ì¤‘ì¹˜ ì ìš©
        total_regret = (
            attachment * 0.3 +      # 30%
            regret * 0.25 +         # 25%
            unresolved * 0.2 +      # 20%
            comparison * 0.15 +    # 15%
            avoidance * 0.1         # 10%
        )
        
        return {
            "total": total_regret,
            "attachment": attachment,
            "regret": regret,
            "unresolved": unresolved,
            "comparison": comparison,
            "avoidance": avoidance
        }
    
    def _generate_emotion_report(self, analysis_results: Dict[str, float], username: str) -> str:
        """ê°ì • ë¦¬í¬íŠ¸ ìƒì„±"""
        total = analysis_results["total"]
        
        # ë¯¸ë ¨ë„ ì§€ìˆ˜ë³„ í•´ì„
        if total <= 20:
            level = "ì™„ì „ ì •ë¦¬ ë‹¨ê³„"
            emoji = "ğŸ’š"
            description = "ì´ë¯¸ ë§ˆìŒì˜ ì •ë¦¬ê°€ ì™„ì „íˆ ëë‚œ ìƒíƒœì˜ˆìš”. ê³¼ê±°ë¥¼ ëŒì•„ë³´ì§€ ì•Šê³  ìƒˆë¡œìš´ ì‹œì‘ì„ ì¤€ë¹„í•˜ê³  ìˆì–´ìš”."
        elif total <= 40:
            level = "ì”ì”í•œ ì—¬ìš´ ë‹¨ê³„"
            emoji = "ğŸ’›"
            description = "ê²‰ìœ¼ë¡œëŠ” ë‹¤ ëë‚œ ë“¯ ë³´ì´ì§€ë§Œ, ê·¸ ì‹œì ˆì˜ ë”°ëœ»í•¨ì„ ì—¬ì „íˆ ê°„ì§í•˜ê³  ìˆì–´ìš”. 'ê·¸ ì‚¬ëŒ'ë³´ë‹¤ëŠ” 'ê·¸ë•Œì˜ ë‚˜'ë¥¼ ê·¸ë¦¬ì›Œí•˜ëŠ” ìƒíƒœì˜ˆìš”."
        elif total <= 60:
            level = "ì ë‹¹í•œ ë¯¸ë ¨ ë‹¨ê³„"
            emoji = "ğŸ§¡"
            description = "ì•„ì§ë„ ê·¸ ì‚¬ëŒì— ëŒ€í•œ ê°ì •ì´ ë‚¨ì•„ìˆì–´ìš”. ì™„ì „íˆ ìŠì§€ëŠ” ëª»í–ˆì§€ë§Œ, ìƒˆë¡œìš´ ì‹œì‘ì„ ìœ„í•œ ì¤€ë¹„ëŠ” ë˜ì–´ìˆì–´ìš”."
        elif total <= 80:
            level = "ê°•í•œ ë¯¸ë ¨ ë‹¨ê³„"
            emoji = "â¤ï¸"
            description = "ì•„ì§ë„ ê·¸ ì‚¬ëŒì— ëŒ€í•œ ê°•í•œ ê°ì •ì´ ë‚¨ì•„ìˆì–´ìš”. ìƒˆë¡œìš´ ê´€ê³„ë¥¼ ì‹œì‘í•˜ê¸°ì—ëŠ” ì•„ì§ ì‹œê°„ì´ ë” í•„ìš”í•  ê²ƒ ê°™ì•„ìš”."
        else:
            level = "ë§¤ìš° ê°•í•œ ë¯¸ë ¨ ë‹¨ê³„"
            emoji = "ğŸ’”"
            description = "ì•„ì§ë„ ê·¸ ì‚¬ëŒì— ëŒ€í•œ ë§¤ìš° ê°•í•œ ê°ì •ì´ ë‚¨ì•„ìˆì–´ìš”. ì™„ì „í•œ ì •ë¦¬ê°€ í•„ìš”í•´ ë³´ì—¬ìš”."
        
        # ì£¼ìš” ê°ì • í‚¤ì›Œë“œ ì¶”ì¶œ
        keywords = []
        if analysis_results["attachment"] > 60:
            keywords.append("#ê·¸ë¦¬ì›€")
        if analysis_results["regret"] > 60:
            keywords.append("#í›„íšŒ")
        if analysis_results["unresolved"] > 60:
            keywords.append("#ë¯¸í•´ê²°ê°")
        if analysis_results["comparison"] > 60:
            keywords.append("#ë¹„êµ")
        if analysis_results["avoidance"] > 60:
            keywords.append("#íšŒí”¼")
        
        if not keywords:
            keywords = ["#ì„±ì¥", "#ì´í•´", "#ì •ë¦¬"]
        
        report = f"""[{username}ë‹˜ì˜ ì—°ì•  ê°ì • ë¦¬í¬íŠ¸]

1ï¸âƒ£ ì£¼ìš” ê°ì • í‚¤ì›Œë“œ
{' '.join(keywords)}

2ï¸âƒ£ ê°ì • ìƒíƒœ ë¶„ì„
"{description}"

3ï¸âƒ£ ë¯¸ë ¨ë„ ì§€ìˆ˜
{emoji} **{int(total)}% â€” {level}**

4ï¸âƒ£ ê°œì¸í™”ëœ ë©”ì‹œì§€
"""
        
        # ê°œì¸í™”ëœ ì¡°ì–¸ ì¶”ê°€
        if total <= 20:
            report += "ê³¼ê±°ë¥¼ ì•„ë¦„ë‹µê²Œ ì •ë¦¬í•˜ê³  ìƒˆë¡œìš´ ì‹œì‘ì„ ì¤€ë¹„í•˜ê³  ìˆëŠ” ëª¨ìŠµì´ ì •ë§ ë©‹ì ¸ìš”. ì´ì œ ì§„ì§œ ìƒˆë¡œìš´ ì‚¬ë‘ì„ ë§Œë‚  ì¤€ë¹„ê°€ ë˜ì–´ìˆì–´ìš”!"
        elif total <= 40:
            report += "ì•„ì§ë„ ê·¸ ì‹œì ˆì˜ ë”°ëœ»í•¨ì„ ê°„ì§í•˜ê³  ìˆì§€ë§Œ, ì´ì œëŠ” 'ê·¸ ì‚¬ëŒ'ë³´ë‹¤ëŠ” 'ê·¸ë•Œì˜ ë‚˜'ë¥¼ ê·¸ë¦¬ì›Œí•˜ê³  ìˆì–´ìš”. ì´ëŠ” ì •ë§ ê±´ê°•í•œ ê°ì •ì´ì—ìš”!"
        elif total <= 60:
            report += "ì•„ì§ë„ ê·¸ ì‚¬ëŒì— ëŒ€í•œ ê°ì •ì´ ë‚¨ì•„ìˆì§€ë§Œ, ì´ì œëŠ” ìƒˆë¡œìš´ ì‹œì‘ì„ ìœ„í•œ ì¤€ë¹„ê°€ ë˜ì–´ìˆì–´ìš”. ì¡°ê¸ˆ ë” ì‹œê°„ì„ ê°–ê³  ì²œì²œíˆ ë‚˜ì•„ê°€ì„¸ìš”!"
        elif total <= 80:
            report += "ì•„ì§ë„ ê·¸ ì‚¬ëŒì— ëŒ€í•œ ê°•í•œ ê°ì •ì´ ë‚¨ì•„ìˆì–´ìš”. ìƒˆë¡œìš´ ê´€ê³„ë¥¼ ì‹œì‘í•˜ê¸°ì—ëŠ” ì•„ì§ ì‹œê°„ì´ ë” í•„ìš”í•  ê²ƒ ê°™ì•„ìš”. ì¡°ê¸ˆ ë” ê¸°ë‹¤ë ¤ë³´ì„¸ìš”!"
        else:
            report += "ì•„ì§ë„ ê·¸ ì‚¬ëŒì— ëŒ€í•œ ë§¤ìš° ê°•í•œ ê°ì •ì´ ë‚¨ì•„ìˆì–´ìš”. ì™„ì „í•œ ì •ë¦¬ê°€ í•„ìš”í•´ ë³´ì—¬ìš”. ì „ë¬¸ê°€ì˜ ë„ì›€ì„ ë°›ëŠ” ê²ƒë„ ì¢‹ì€ ë°©ë²•ì´ì—ìš”!"
        
        return report
    
    
    def _load_config(self):
        """
        ì„¤ì • íŒŒì¼ ë¡œë“œ
        
        TODO: config/chatbot_config.json ì½ì–´ì„œ ë°˜í™˜
        
        ë°˜í™˜ê°’ ì˜ˆì‹œ:
        {
            "name": "ê¹€ì„œê°•",
            "character": {...},
            "system_prompt": {...}
        }
        """
        config_path = BASE_DIR / "config" / "chatbot_config.json"
        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        except FileNotFoundError:
            print(f"[WARNING] ì„¤ì • íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {config_path}")
            return {
                "name": "í™˜ìŠ¹ì—°ì•  PD ì¹œêµ¬",
                "description": "í™˜ìŠ¹ì—°ì• íŒ€ ë§‰ë‚´ PD ì¹œêµ¬",
                "system_prompt": {
                    "base": "ë‹¹ì‹ ì€ í™˜ìŠ¹ì—°ì• íŒ€ ë§‰ë‚´ PDê°€ ëœ ì¹œêµ¬ì…ë‹ˆë‹¤.",
                    "rules": ["ì¹œê·¼í•˜ê²Œ ëŒ€í™”í•˜ì„¸ìš”", "ì—°ì•  ì´ì•¼ê¸°ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ì´ëŒì–´ë‚´ì„¸ìš”"]
                }
            }
    
    
    def _init_chromadb(self):
        """
        ChromaDB ì´ˆê¸°í™” ë° ì»¬ë ‰ì…˜ ë°˜í™˜
        
        TODO: 
        1. PersistentClient ìƒì„±
        2. ì»¬ë ‰ì…˜ ê°€ì ¸ì˜¤ê¸° (ì´ë¦„: "rag_collection")
        3. ì»¬ë ‰ì…˜ ë°˜í™˜
        
        íŒíŠ¸:
        - import chromadb
        - db_path = BASE_DIR / "static/data/chatbot/chardb_embedding"
        - client = chromadb.PersistentClient(path=str(db_path))
        - collection = client.get_collection(name="rag_collection")
        """
        db_path = BASE_DIR / "static/data/chatbot/chardb_embedding"
        db_path.mkdir(parents=True, exist_ok=True)
        
        client = None
        try:
            client = chromadb.PersistentClient(path=str(db_path))
            try:
                collection = client.get_collection(name="rag_collection")
                print(f"[ChromaDB] ì»¬ë ‰ì…˜ ì—°ê²° ì„±ê³µ: {collection.name}")
                return collection
            except Exception:
                # ì—†ìœ¼ë©´ ìƒì„±
                collection = client.create_collection(name="rag_collection")
                print(f"[ChromaDB] ìƒˆ ì»¬ë ‰ì…˜ ìƒì„±: {collection.name}")
                return collection
        except Exception as e:
            print(f"[WARNING] ChromaDB ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return None
    
    
    def _create_embedding(self, text: str) -> list:
        """
        í…ìŠ¤íŠ¸ë¥¼ ì„ë² ë”© ë²¡í„°ë¡œ ë³€í™˜
        
        Args:
            text (str): ì„ë² ë”©í•  í…ìŠ¤íŠ¸
        
        Returns:
            list: 3072ì°¨ì› ë²¡í„° (text-embedding-3-large ëª¨ë¸)
        
        TODO:
        1. OpenAI API í˜¸ì¶œ
        2. embeddings.create() ì‚¬ìš©
        3. ë²¡í„° ë°˜í™˜
        
        íŒíŠ¸:
        - response = self.client.embeddings.create(
        -     input=[text],
        -     model="text-embedding-3-large"
        - )
        - return response.data[0].embedding
        """
        if not self.client:
            return []
        try:
            response = self.client.embeddings.create(
                input=[text],
                model="text-embedding-3-large"
            )
            return response.data[0].embedding
        except Exception as e:
            print(f"[ERROR] ì„ë² ë”© ìƒì„± ì‹¤íŒ¨: {e}")
            return []
    
    
    def _search_similar(self, query: str, threshold: float = 0.45, top_k: int = 5):
        """
        RAG ê²€ìƒ‰: ìœ ì‚¬í•œ ë¬¸ì„œ ì°¾ê¸° (í•µì‹¬ ë©”ì„œë“œ!)
        
        Args:
            query (str): ê²€ìƒ‰ ì§ˆì˜
            threshold (float): ìœ ì‚¬ë„ ì„ê³„ê°’ (0.3-0.5 ê¶Œì¥)
            top_k (int): ê²€ìƒ‰í•  ë¬¸ì„œ ê°œìˆ˜
        
        Returns:
            tuple: (document, similarity, metadata) ë˜ëŠ” (None, None, None)
        
        TODO: RAG ê²€ìƒ‰ ì•Œê³ ë¦¬ì¦˜ êµ¬í˜„
        
        1. ì¿¼ë¦¬ ì„ë² ë”© ìƒì„±
           query_embedding = self._create_embedding(query)
        
        2. ChromaDB ê²€ìƒ‰
           results = self.collection.query(
               query_embeddings=[query_embedding],
               n_results=top_k,
               include=["documents", "distances", "metadatas"]
           )
        
        3. ìœ ì‚¬ë„ ê³„ì‚° ë° í•„í„°ë§
           for doc, dist, meta in zip(...):
               similarity = 1 / (1 + dist)  â† ìœ ì‚¬ë„ ê³µì‹!
               if similarity >= threshold:
                   ...
        
        4. ê°€ì¥ ìœ ì‚¬í•œ ë¬¸ì„œ ë°˜í™˜
           return (best_document, best_similarity, metadata)
        
        
        ğŸ’¡ í•µì‹¬ ê°œë…:
        
        - Distance vs Similarity
          Â· ChromaDBëŠ” "ê±°ë¦¬(distance)"ë¥¼ ë°˜í™˜ (ì‘ì„ìˆ˜ë¡ ìœ ì‚¬)
          Â· ìš°ë¦¬ëŠ” "ìœ ì‚¬ë„(similarity)"ë¡œ ë³€í™˜ (í´ìˆ˜ë¡ ìœ ì‚¬)
          Â· ë³€í™˜ ê³µì‹: similarity = 1 / (1 + distance)
        
        - Threshold
          Â· 0.3: ë§¤ìš° ëŠìŠ¨í•œ ë§¤ì¹­ (ê´€ë ¨ì„± ë‚®ì•„ë„ OK)
          Â· 0.45: ì ë‹¹í•œ ë§¤ì¹­ (ì¶”ì²œ!)
          Â· 0.7: ë§¤ìš° ì—„ê²©í•œ ë§¤ì¹­ (ì •í™•í•œ ë‹µë§Œ)
        
        - Top K
          Â· 5-10ê°œ ì •ë„ ê²€ìƒ‰
          Â· ê·¸ ì¤‘ threshold ë„˜ëŠ” ê²ƒë§Œ ì‚¬ìš©
        
        
        ğŸ› ë””ë²„ê¹… íŒ:
        - print()ë¡œ ê²€ìƒ‰ ê²°ê³¼ í™•ì¸
        - ìœ ì‚¬ë„ ê°’ í™•ì¸ (ë„ˆë¬´ ë‚®ìœ¼ë©´ threshold ì¡°ì •)
        - ê²€ìƒ‰ëœ ë¬¸ì„œ ë‚´ìš© í™•ì¸
        """
        if not self.collection:
            print("[WARNING] ChromaDB ì»¬ë ‰ì…˜ì´ ì—†ìŠµë‹ˆë‹¤.")
            return None, None, None
        
        try:
            # 1. ì¿¼ë¦¬ ì„ë² ë”© ìƒì„± (LLM ë¹„í™œì„±í™” ì‹œ RAG ìƒëµ)
            if not self.client:
                return None, None, None
            query_embedding = self._create_embedding(query)
            if not query_embedding:
                return None, None, None
            
            # 2. ChromaDB ê²€ìƒ‰
            results = self.collection.query(
                query_embeddings=[query_embedding],
                n_results=top_k,
                include=["documents", "distances", "metadatas"]
            )
            
            # 3. ìœ ì‚¬ë„ ê³„ì‚° ë° í•„í„°ë§
            best_document = None
            best_similarity = 0
            best_metadata = None
            
            if results['documents'] and results['documents'][0]:
                for doc, dist, meta in zip(
                    results['documents'][0], 
                    results['distances'][0], 
                    results['metadatas'][0]
                ):
                    similarity = 1 / (1 + dist)  # ìœ ì‚¬ë„ ê³µì‹
                    print(f"[RAG] ìœ ì‚¬ë„: {similarity:.4f}, ê±°ë¦¬: {dist:.4f}")
                    
                    if similarity >= threshold and similarity > best_similarity:
                        best_document = doc
                        best_similarity = similarity
                        best_metadata = meta
            
            if best_document:
                print(f"[RAG] ìµœê³  ìœ ì‚¬ë„: {best_similarity:.4f}")
                print(f"[RAG] ë¬¸ì„œ: {best_document[:100]}...")
                return best_document, best_similarity, best_metadata
            else:
                print(f"[RAG] ì„ê³„ê°’({threshold}) ì´ìƒì˜ ìœ ì‚¬í•œ ë¬¸ì„œë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                return None, None, None
                
        except Exception as e:
            print(f"[ERROR] RAG ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return None, None, None
    
    
    def _build_prompt(self, user_message: str, context: str = None, username: str = "ì‚¬ìš©ì"):
        """
        LLM í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        
        Args:
            user_message (str): ì‚¬ìš©ì ë©”ì‹œì§€
            context (str): RAG ê²€ìƒ‰ ê²°ê³¼ (ì„ íƒ)
            username (str): ì‚¬ìš©ì ì´ë¦„
        
        Returns:
            str: ìµœì¢… í”„ë¡¬í”„íŠ¸
        
        TODO:
        1. ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ê°€ì ¸ì˜¤ê¸° (configì—ì„œ)
        2. RAG ì»¨í…ìŠ¤íŠ¸ í¬í•¨ ì—¬ë¶€ ê²°ì •
        3. ëŒ€í™” ê¸°ë¡ í¬í•¨ (ì„ íƒ)
        4. ìµœì¢… í”„ë¡¬í”„íŠ¸ ë¬¸ìì—´ ë°˜í™˜
        
        í”„ë¡¬í”„íŠ¸ ì˜ˆì‹œ:
        ```
        ë‹¹ì‹ ì€ ì„œê°•ëŒ€í•™êµ ì„ ë°° ê¹€ì„œê°•ì…ë‹ˆë‹¤.
        ì‹ ì…ìƒë“¤ì—ê²Œ í•™êµ ìƒí™œì„ ì•Œë ¤ì£¼ëŠ” ì—­í• ì„ í•©ë‹ˆë‹¤.
        
        [ì°¸ê³  ì •ë³´]  â† RAG ì»¨í…ìŠ¤íŠ¸ê°€ ìˆì„ ë•Œë§Œ
        í•™ì‹ì€ ê³¤ìê°€ê°€ ë§›ìˆì–´. ëˆê¹ŒìŠ¤ê°€ ì¸ê¸°ì•¼.
        
        ì‚¬ìš©ì: í•™ì‹ ì¶”ì²œí•´ì¤˜
        ```
        """
        # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        system_prompt = self.config.get('system_prompt', {})
        base_prompt = system_prompt.get('base', 'ë‹¹ì‹ ì€ í™˜ìŠ¹ì—°ì• íŒ€ ë§‰ë‚´ PDê°€ ëœ ì¹œêµ¬ì…ë‹ˆë‹¤.')
        rules = system_prompt.get('rules', [])
        
        # ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        prompt_parts = [base_prompt]
        
        # ê·œì¹™ ì¶”ê°€
        if rules:
            prompt_parts.append("\n".join([f"- {rule}" for rule in rules]))
        
        # RAG ì»¨í…ìŠ¤íŠ¸ ì¶”ê°€
        if context:
            prompt_parts.append(f"\n[ì°¸ê³  ì •ë³´]\n{context}")
        
        # ëŒ€í™” ê¸°ë¡ ì¶”ê°€ (ì„ íƒ)
        if self.memory:
            try:
                memory_vars = self.memory.load_memory_variables({})
                if memory_vars and 'history' in memory_vars:
                    prompt_parts.append(f"\n[ëŒ€í™” ê¸°ë¡]\n{memory_vars['history']}")
            except Exception as e:
                print(f"[WARNING] ë©”ëª¨ë¦¬ ë¡œë“œ ì‹¤íŒ¨: {e}")
        
        # ëŒ€í™” ì§€ì¹¨ ì¶”ê°€
        prompt_parts.append("\nëŒ€í™” ì§€ì¹¨:")
        prompt_parts.append("- ì¹œêµ¬ì²˜ëŸ¼ í¸í•˜ê²Œ ë°˜ë§ë¡œ ëŒ€í™”í•´")
        prompt_parts.append("- ë„ˆë¬´ ìƒì„¸í•˜ê²Œ ê³„ì† ë¬¼ì–´ë³´ì§€ ë§ê³ , ì ë‹¹í•œ íƒ€ì´ë°ì— ë‹¤ë¥¸ ì£¼ì œë¡œ ë„˜ì–´ê°€")
        prompt_parts.append("- ì—°ì•  ì´ì•¼ê¸°ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ì´ëŒì–´ë‚´ë˜, ë¬´ë¦¬í•˜ê²Œ ëŒì–´ë‚´ì§€ ë§ˆ")
        prompt_parts.append("- ì´ëª¨í‹°ì½˜ì€ ìµœì†Œí•œìœ¼ë¡œ ì‚¬ìš©í•´")
        
        # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
        prompt_parts.append(f"\n{username}: {user_message}")
        
        return "\n".join(prompt_parts)
    
    
    def generate_response(self, user_message: str, username: str = "ì‚¬ìš©ì") -> dict:
        """
        ì‚¬ìš©ì ë©”ì‹œì§€ì— ëŒ€í•œ ì±—ë´‡ ì‘ë‹µ ìƒì„±
        
        Args:
            user_message (str): ì‚¬ìš©ì ì…ë ¥
            username (str): ì‚¬ìš©ì ì´ë¦„
        
        Returns:
            dict: {
                'reply': str,       # ì±—ë´‡ ì‘ë‹µ í…ìŠ¤íŠ¸
                'image': str|None   # ì´ë¯¸ì§€ ê²½ë¡œ (ì„ íƒ)
            }
        
        
        TODO: ì „ì²´ ì‘ë‹µ ìƒì„± íŒŒì´í”„ë¼ì¸ êµ¬í˜„
        
        
        â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        ğŸ“‹ êµ¬í˜„ ë‹¨ê³„
        â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        
        [1ë‹¨ê³„] ì´ˆê¸° ë©”ì‹œì§€ ì²˜ë¦¬
        
            if user_message.strip().lower() == "init":
                # ì²« ì¸ì‚¬ë§ ë°˜í™˜
                bot_name = self.config.get('name', 'ì±—ë´‡')
                return {
                    'reply': f"ì•ˆë…•! ë‚˜ëŠ” {bot_name}ì´ì•¼.",
                    'image': None
                }
        
        
        [2ë‹¨ê³„] RAG ê²€ìƒ‰ ìˆ˜í–‰
        
            context, similarity, metadata = self._search_similar(
                query=user_message,
                threshold=0.45,
                top_k=5
            )
            
            has_context = (context is not None)
        
        
        [3ë‹¨ê³„] í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        
            prompt = self._build_prompt(
                user_message=user_message,
                context=context,
                username=username
            )
        
        
        [4ë‹¨ê³„] LLM API í˜¸ì¶œ
        
            response = self.client.chat.completions.create(
                model="gpt-4o-mini",  # ë˜ëŠ” gpt-4
                messages=[
                    {"role": "system", "content": "ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸"},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.7,
                max_tokens=500
            )
            
            reply = response.choices[0].message.content
        
        
        [5ë‹¨ê³„] ë©”ëª¨ë¦¬ ì €ì¥ (ì„ íƒ)
        
            if self.memory:
                self.memory.save_context(
                    {"input": user_message},
                    {"output": reply}
                )
        
        
        [6ë‹¨ê³„] ì‘ë‹µ ë°˜í™˜
        
            return {
                'reply': reply,
                'image': None  # ì´ë¯¸ì§€ ê²€ìƒ‰ ë¡œì§ ì¶”ê°€ ê°€ëŠ¥
            }
        
        
        â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        ğŸ’¡ í•µì‹¬ í¬ì¸íŠ¸
        â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        
        1. RAG í™œìš©
           - ê²€ìƒ‰ ê²°ê³¼ê°€ ìˆìœ¼ë©´ í”„ë¡¬í”„íŠ¸ì— í¬í•¨
           - ì—†ìœ¼ë©´ ì¼ë°˜ ëŒ€í™” ëª¨ë“œ
        
        2. ì—ëŸ¬ ì²˜ë¦¬
           - try-exceptë¡œ API ì˜¤ë¥˜ ì²˜ë¦¬
           - ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ì‘ë‹µ ë°˜í™˜
        
        3. ë¡œê¹…
           - ê° ë‹¨ê³„ë§ˆë‹¤ print()ë¡œ ìƒíƒœ ì¶œë ¥
           - ë””ë²„ê¹…ì— ë§¤ìš° ìœ ìš©!
        
        4. í™•ì¥ì„±
           - ì´ë¯¸ì§€ ê²€ìƒ‰ ë¡œì§ ì¶”ê°€ ê°€ëŠ¥
           - ê°ì • ë¶„ì„ ì¶”ê°€ ê°€ëŠ¥
           - ë‹¤ì¤‘ ì–¸ì–´ ì§€ì› ê°€ëŠ¥
        
        
        â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        ğŸ› ë””ë²„ê¹… ì˜ˆì‹œ
        â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        
        print(f"\n{'='*50}")
        print(f"[USER] {username}: {user_message}")
        print(f"[RAG] Context found: {has_context}")
        if has_context:
            print(f"[RAG] Similarity: {similarity:.4f}")
            print(f"[RAG] Context: {context[:100]}...")
        print(f"[LLM] Calling API...")
        print(f"[BOT] {reply}")
        print(f"{'='*50}\n")
        """
        
        # ì—¬ê¸°ì— ì „ì²´ íŒŒì´í”„ë¼ì¸ êµ¬í˜„
        # ìœ„ì˜ ë‹¨ê³„ë¥¼ ì°¸ê³ í•˜ì—¬ ììœ ë¡­ê²Œ ì„¤ê³„í•˜ì„¸ìš”
        
        try:
            print(f"\n{'='*50}")
            print(f"[USER] {username}: {user_message}")
            
            # [1ë‹¨ê³„] ì´ˆê¸° ë©”ì‹œì§€ ì²˜ë¦¬
            if user_message.strip().lower() == "init":
                bot_name = self.config.get('name', 'í™˜ìŠ¹ì—°ì•  PD ì¹œêµ¬')
                return {
                    'reply': f"ì•¼, {username}! ë‚˜ ì´ë²ˆì— í™˜ìŠ¹ì—°ì•  íŒ€ ë§‰ë‚´ PD ëì–ì•„. ê·¼ë° ì§€ê¸ˆ ìƒˆ í”„ë¡œê·¸ë¨ ê¸°íš ì¤‘ì¸ë°, ì†”ì§íˆ ì‚¬ëŒë“¤ ì—°ì•  ì–˜ê¸° ì¢€ ëª¨ìœ¼ê³  ìˆì–´. ë„ˆ ì „ ì—°ì•  ì–˜ê¸° ì¢€ í•´ì¤„ ìˆ˜ ìˆì–´?",
                    'image': None
                }
            
            # [2ë‹¨ê³„] RAG ê²€ìƒ‰ ìˆ˜í–‰
            context, similarity, metadata = self._search_similar(
                query=user_message,
                threshold=0.45,
                top_k=5
            )
            
            has_context = (context is not None)
            print(f"[RAG] Context found: {has_context}")
            if has_context:
                print(f"[RAG] Similarity: {similarity:.4f}")
                print(f"[RAG] Context: {context[:100]}...")
            
            # [3ë‹¨ê³„] ì—°ì•  ê°ì • ë¶„ì„ ìˆ˜í–‰
            analysis_results = self._calculate_regret_index(user_message)
            print(f"[ANALYSIS] ë¯¸ë ¨ë„: {analysis_results['total']:.1f}%")
            
            # [4ë‹¨ê³„] í”„ë¡¬í”„íŠ¸ êµ¬ì„±
            prompt = self._build_prompt(
                user_message=user_message,
                context=context,
                username=username
            )
            
            # [5ë‹¨ê³„] LLM API í˜¸ì¶œ
            if self.client:
                print(f"[LLM] Calling API...")
                response = self.client.chat.completions.create(
                    model="gpt-4o-mini",
                    messages=[
                        {"role": "system", "content": "ë‹¹ì‹ ì€ í™˜ìŠ¹ì—°ì• íŒ€ ë§‰ë‚´ PDê°€ ëœ ì¹œêµ¬ì…ë‹ˆë‹¤. ì‚¬ìš©ìì™€ ë°˜ë§ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ëŒ€í™”í•˜ë©°, ì—°ì•  ì´ì•¼ê¸°ë¥¼ ë“£ê³  ë¯¸ë ¨ë„ë¥¼ ë¶„ì„í•´ì£¼ëŠ” ì—­í• ì„ í•©ë‹ˆë‹¤. ì¹œêµ¬ì²˜ëŸ¼ í¸í•˜ê²Œ ëŒ€í™”í•˜ê³ , ì´ëª¨í‹°ì½˜ì€ ìµœì†Œí•œìœ¼ë¡œ ì‚¬ìš©í•˜ì„¸ìš”. ë„ˆë¬´ ìƒì„¸í•˜ê²Œ ê³„ì† ë¬¼ì–´ë³´ì§€ ë§ê³ , ì ë‹¹í•œ íƒ€ì´ë°ì— ë‹¤ë¥¸ ì£¼ì œë¡œ ë„˜ì–´ê°€ê±°ë‚˜ ë¶„ì„ ê²°ê³¼ë¥¼ ì œì‹œí•˜ì„¸ìš”. ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™” íë¦„ì„ ìœ ì§€í•˜ì„¸ìš”."},
                        {"role": "user", "content": prompt}
                    ],
                    temperature=0.7,
                    max_tokens=500
                )
                reply = response.choices[0].message.content
            else:
                # LLM ë¹„í™œì„±í™” ì‹œ ê¸°ë³¸ ì‘ë‹µ
                reply = "AI ì—°ì•  ë¶„ì„ ì—ì´ì „íŠ¸ ë°ëª¨ ëª¨ë“œì•¼. í™˜ê²½ë³€ìˆ˜ ì„¤ì • í›„ ë” ì •êµí•œ ë¶„ì„ì´ ê°€ëŠ¥í•´! ë¨¼ì € ì–´ë–¤ ì´ì•¼ê¸°ë¶€í„° ì‹œì‘í• ê¹Œ?"
            
            # [6ë‹¨ê³„] ê°ì • ë¦¬í¬íŠ¸ ìƒì„± (íŠ¹ì • ì¡°ê±´ì—ì„œ)
            if any(keyword in user_message.lower() for keyword in ["ë¶„ì„", "ë¦¬í¬íŠ¸", "ê²°ê³¼", "ì–´ë•Œ", "ì–´ë–¤"]):
                if analysis_results['total'] > 0:  # ë¶„ì„ ê²°ê³¼ê°€ ìˆì„ ë•Œë§Œ
                    report = self._generate_emotion_report(analysis_results, username)
                    reply += f"\n\n{report}"
            
            # [7ë‹¨ê³„] ë©”ëª¨ë¦¬ ì €ì¥
            if self.memory:
                try:
                    self.memory.save_context(
                        {"input": user_message},
                        {"output": reply}
                    )
                except Exception as e:
                    print(f"[WARNING] ë©”ëª¨ë¦¬ ì €ì¥ ì‹¤íŒ¨: {e}")
            
            print(f"[BOT] {reply[:100]}...")
            print(f"{'='*50}\n")
            
            # [8ë‹¨ê³„] ì‘ë‹µ ë°˜í™˜
            return {
                'reply': reply,
                'image': None
            }
            
        except Exception as e:
            print(f"[ERROR] ì‘ë‹µ ìƒì„± ì‹¤íŒ¨: {e}")
            return {
                'reply': "ì£„ì†¡í•´ìš”, ì¼ì‹œì ì¸ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆì–´ìš”. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.",
                'image': None
            }


# ============================================================================
# ì‹±ê¸€í†¤ íŒ¨í„´
# ============================================================================
# ChatbotService ì¸ìŠ¤í„´ìŠ¤ë¥¼ ì•± ì „ì²´ì—ì„œ ì¬ì‚¬ìš©
# (ë§¤ë²ˆ ìƒˆë¡œ ì´ˆê¸°í™”í•˜ë©´ ë¹„íš¨ìœ¨ì )

_chatbot_service = None

def get_chatbot_service():
    """
    ì±—ë´‡ ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜ (ì‹±ê¸€í†¤)
    
    ì²« í˜¸ì¶œ ì‹œ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±, ì´í›„ ì¬ì‚¬ìš©
    """
    global _chatbot_service
    if _chatbot_service is None:
        _chatbot_service = ChatbotService()
    return _chatbot_service


# ============================================================================
# í…ŒìŠ¤íŠ¸ìš© ë©”ì¸ í•¨ìˆ˜
# ============================================================================

if __name__ == "__main__":
    """
    ë¡œì»¬ í…ŒìŠ¤íŠ¸ìš©
    
    ì‹¤í–‰ ë°©ë²•:
    python services/chatbot_service.py
    """
    print("ì±—ë´‡ ì„œë¹„ìŠ¤ í…ŒìŠ¤íŠ¸")
    print("=" * 50)
    
    service = get_chatbot_service()
    
    # ì´ˆê¸°í™” í…ŒìŠ¤íŠ¸
    response = service.generate_response("init", "í…ŒìŠ¤í„°")
    print(f"ì´ˆê¸° ì‘ë‹µ: {response}")
    
    # ì¼ë°˜ ëŒ€í™” í…ŒìŠ¤íŠ¸
    response = service.generate_response("ì•ˆë…•í•˜ì„¸ìš”!", "í…ŒìŠ¤í„°")
    print(f"ì‘ë‹µ: {response}")
